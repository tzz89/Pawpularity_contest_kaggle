{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Strategy\n1. Basemodel with effnetB0\n    - n_fold cross validation (done)\n    - integrate weight and biases (done)\n    - fp16 (done, swinTransformer was not able to learn with fp16)\n    - cosine annealing scheduler (done)\n    - gradcam (done, seperate notebook)\n2. retry with swinTransfomer\n3. Augmentation (done)\n    - Random left right flip \n    - Random Crop resized \n    \n    \n<!-- 4. Blur detection\n5. Dog cat detection\n6. Multi-pet (group) detection\n7. % coverage detection -->","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install timm\n!pip install wandb --upgrade","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:02:55.917091Z","iopub.execute_input":"2021-11-22T14:02:55.917537Z","iopub.status.idle":"2021-11-22T14:03:16.194866Z","shell.execute_reply.started":"2021-11-22T14:02:55.917418Z","shell.execute_reply":"2021-11-22T14:03:16.194035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pytorch lib\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\nimport timm\n\n\n# image agumentation lib\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# numeric lib\nimport numpy as np\nimport pandas as pd\n\n# image library\nfrom PIL import Image\n\n#python lib\nimport random\nimport os\nimport tqdm\n\n# ploting library\nimport matplotlib.pyplot as plt\nimport wandb \n\n#sklearn library\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:03:16.198752Z","iopub.execute_input":"2021-11-22T14:03:16.198979Z","iopub.status.idle":"2021-11-22T14:03:24.050229Z","shell.execute_reply.started":"2021-11-22T14:03:16.198952Z","shell.execute_reply":"2021-11-22T14:03:24.049439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config File","metadata":{}},{"cell_type":"code","source":"class Config:\n    seed = 42\n    epochs = 5\n    train_img_dir = \"../input/petfinder-pawpularity-score/train\"\n    image_size = 384\n    n_splits = 5\n    model_name = 'swin_large_patch4_window12_384' #'efficientnet_b0'\n    train_batchsize = 8\n    val_batchsize = 8\n    debug = False\n    \n    fp16 = False\n    \n    #optimizer\n    optimizer = \"Adam\"\n    \n    if optimizer == \"Adam\":\n        optimizer_params = dict(\n            lr = 1e-4,\n            betas = (0.9, 0.999),\n            eps = 1e-8,\n            weight_decay = 0,\n            amsgrad = False\n        )\n        \n    elif optimizer == \"SGD\":\n        optimizer_params = dict(\n            lr = 1e-3,\n            weight_decay = 0,\n            dampening  = 0,\n            nesterov = False\n        ) \n        \n    # Scheduler\n    scheduler = 'CosineAnnealingLR' # CosineAnnealingLR, ReduceLROnPlateau\n    if scheduler == \"CosineAnnealingLR\":\n        scheduler_params = dict(\n            T_max = epochs,\n            eta_min = 0,\n            last_epoch = -1,\n            verbose = False\n        )\n    elif scheduler == \"ReduceLROnPlateau\":\n        scheduler_params = dict(\n            mode = \"min\",\n            factor= 0.1,\n            patience=4,\n            threshold=1e-4,\n            min_lr = 1e-6\n        )","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:03:24.051622Z","iopub.execute_input":"2021-11-22T14:03:24.051927Z","iopub.status.idle":"2021-11-22T14:03:24.061414Z","shell.execute_reply.started":"2021-11-22T14:03:24.05189Z","shell.execute_reply":"2021-11-22T14:03:24.059362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## login to wandb and create project\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandkey = user_secrets.get_secret(\"wand_key\")\n\n\ndef class2dict(f):\n    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n\nwandb.login(key=wandkey)\nrun = wandb.init(project=\"Pawpularity\",\n                 name=Config.model_name,\n                 config = class2dict(Config),\n                 group=Config.model_name)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:03:24.062756Z","iopub.execute_input":"2021-11-22T14:03:24.063236Z","iopub.status.idle":"2021-11-22T14:03:31.839075Z","shell.execute_reply.started":"2021-11-22T14:03:24.0632Z","shell.execute_reply":"2021-11-22T14:03:31.838346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Seed everything","metadata":{}},{"cell_type":"code","source":"def seed_python(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \ndef seed_torch(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    \nseed_python(Config.seed)\nseed_torch(Config.seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:03:31.841905Z","iopub.execute_input":"2021-11-22T14:03:31.842189Z","iopub.status.idle":"2021-11-22T14:03:31.852813Z","shell.execute_reply.started":"2021-11-22T14:03:31.842139Z","shell.execute_reply":"2021-11-22T14:03:31.852114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ContinuousStratifiedKFold(StratifiedKFold):\n    def __init__(self, *args, **kwargs):\n        super(ContinuousStratifiedKFold, self).__init__(*args, **kwargs)\n    \n    def split(self, X, y, groups=None):\n        n_bins = int(np.floor(1+np.log2(len(y))))\n        new_y = pd.cut(y, n_bins, labels=False)\n        return super().split(X, new_y, groups)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:03:31.854245Z","iopub.execute_input":"2021-11-22T14:03:31.854829Z","iopub.status.idle":"2021-11-22T14:03:31.86211Z","shell.execute_reply.started":"2021-11-22T14:03:31.854775Z","shell.execute_reply":"2021-11-22T14:03:31.861334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss function","metadata":{}},{"cell_type":"code","source":"class RMSELoss(nn.Module):\n    def __init__(self, eps=1e-6):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        self.eps = eps\n\n    def forward(self, yhat, y):\n        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:03:31.864669Z","iopub.execute_input":"2021-11-22T14:03:31.86583Z","iopub.status.idle":"2021-11-22T14:03:31.872686Z","shell.execute_reply.started":"2021-11-22T14:03:31.865793Z","shell.execute_reply":"2021-11-22T14:03:31.872016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ntrain_df['filepath'] = train_df['Id'].map(lambda x : os.path.join(Config.train_img_dir, x+\".jpg\"))\ntrain_df['n_fold'] = -1\n\nif Config.debug:\n    train_df = train_df.sample(300)\n\n    \ntrain_df = train_df.reset_index()\n\nkfold = ContinuousStratifiedKFold(n_splits=Config.n_splits, shuffle=True, random_state= Config.seed)\n\nfor fold_num, (train_idx, test_idx) in enumerate(kfold.split(train_df['Pawpularity'],train_df['Pawpularity'])):\n    train_df.loc[test_idx, \"n_fold\"]= fold_num \n\ntrain_df.to_csv(\"training_kfold.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:03:31.874016Z","iopub.execute_input":"2021-11-22T14:03:31.874439Z","iopub.status.idle":"2021-11-22T14:03:32.081166Z","shell.execute_reply.started":"2021-11-22T14:03:31.874401Z","shell.execute_reply":"2021-11-22T14:03:32.080505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the dataset","metadata":{}},{"cell_type":"code","source":"class PawDataset(Dataset):\n    def __init__(self, image_fps, targets, transforms):\n        super(PawDataset, self).__init__()\n        self.image_fps = image_fps\n        self.transforms = transforms\n        self.targets = targets\n        \n    def __len__(self):\n        return len(self.image_fps)\n    \n    def __getitem__(self, idx):\n        image_fp = self.image_fps[idx]\n        target = torch.tensor(self.targets[idx]).float()\n        \n        img = np.array(Image.open(image_fp))\n        img = self.transforms(image=img)['image']\n        return img, target\n\n# Test\n# transform = A.Compose([\n#     A.Resize(Config.image_size, Config.image_size,p=1),\n#     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1),\n#     ToTensorV2()\n# ], p=1)\n\n# test_dataset = PawDataset([\"../input/petfinder-pawpularity-score/train/0007de18844b0dbbb5e1f607da0606e0.jpg\"], [1], transform)\n# plt.imshow(torch.permute(test_dataset[0][0], (1,2,0)).numpy())","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:03:32.082528Z","iopub.execute_input":"2021-11-22T14:03:32.08277Z","iopub.status.idle":"2021-11-22T14:03:32.094855Z","shell.execute_reply.started":"2021-11-22T14:03:32.082738Z","shell.execute_reply":"2021-11-22T14:03:32.094066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the model","metadata":{}},{"cell_type":"code","source":"class PawModel(nn.Module):\n    def __init__(self, model_name):\n        super(PawModel, self).__init__()\n        self.backbone = timm.create_model(model_name, pretrained=True, in_chans=3) #this will create a model with classifier\n        self.backbone.head = nn.Linear(self.backbone.head.in_features, 128)\n#         self.backbone.classifier = nn.Identity()\n        self.dropout = nn.Dropout(p=0.1)\n        self.fcn = nn.Linear(128, 64)\n        self.output = nn.Linear(64, 1)\n        \n    def forward(self,image_array):\n        x = self.backbone(image_array)\n        x = self.dropout(x)\n        x = self.fcn(x)\n        return self.output(x)\n        \n#Test\n# model = PawModel()\n# model(test_dataset[0][0].unsqueeze(0))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:03:32.096193Z","iopub.execute_input":"2021-11-22T14:03:32.096942Z","iopub.status.idle":"2021-11-22T14:03:32.107983Z","shell.execute_reply.started":"2021-11-22T14:03:32.096903Z","shell.execute_reply":"2021-11-22T14:03:32.107197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper functions","metadata":{}},{"cell_type":"code","source":"class AverageMeter():\n    def __init__(self):\n        self.sum = 0\n        self.count = 0\n        \n    def update(self, value, count):\n        self.count += count\n        self.sum += value*count\n        \n    def get_average(self):\n        return self.sum/self.count\n        \ndef train_step(model, optimizer, train_dataloader, criterion, device,scaler=None):\n    avg_meter = AverageMeter()\n    model.train()\n    progbar = tqdm.tqdm(train_dataloader, desc='Train', total=len(train_dataloader))\n    \n    if scaler is None:\n        for img_array, target in progbar:\n            batchsize = len(target)\n            img_array = img_array.to(device)\n            target = target.to(device)\n            optimizer.zero_grad()\n            y_pred = model(img_array)\n            train_loss = criterion(y_pred.view(-1), target)\n            avg_meter.update(train_loss.item(), batchsize)\n\n            train_loss.backward()\n            optimizer.step()  \n            progbar.set_postfix({\"train_loss\":f\"{avg_meter.get_average():.5f}\"})\n    else:\n        for img_array, target in progbar:\n            batchsize = len(target)\n            img_array = img_array.to(device)\n            target = target.to(device)\n            optimizer.zero_grad()\n            with torch.cuda.amp.autocast():\n                y_pred = model(img_array)\n                train_loss = criterion(y_pred.view(-1), target)\n    \n            avg_meter.update(train_loss.item(), batchsize)\n            scaler.scale(train_loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n    \n            progbar.set_postfix({\"train_loss\":f\"{avg_meter.get_average():.5f}\"})\n\n    return avg_meter.get_average()\n\ndef validate_step(model, val_dataloader, criterion, device):\n    avg_meter = AverageMeter()\n    model.eval()\n    progbar = tqdm.tqdm(val_dataloader, desc=\"Validation\", total=len(val_dataloader))\n    for img_array, target in progbar:\n        batchsize = len(target)\n        img_array = img_array.to(device)\n        target = target.to(device)\n        with torch.no_grad():\n            y_pred = model(img_array)\n            val_loss = criterion(y_pred.view(-1), target)\n            \n        avg_meter.update(val_loss, batchsize)\n        progbar.set_postfix({\"val_loss\":f\"{avg_meter.get_average():.5f}\"})\n        \n    return avg_meter.get_average()\n    \n\ndef get_scheduler(optimizer, config):\n    if Config.scheduler == \"CosineAnnealingLR\":\n        return CosineAnnealingLR(optimizer, **config.scheduler_params)\n    if Config.scheduler == \"ReduceLROnPlateau\":\n        return ReduceLROnPlateau(optimizer, **config.scheduler_params)\n    \ndef get_optimizer(model, config):\n    if config.optimizer == \"Adam\":\n        return torch.optim.Adam(model, **config.optimizer_params)\n    if config.optimizer == \"SGD\":\n        return torch.optim.SGD(model, **config.optimizer_params)\n    \n    raise NotImplementedError\n\ndef get_dataloaders(train_ds, val_ds, train_batchsize=Config.train_batchsize, val_batchsize=Config.val_batchsize):\n    train_transform = A.Compose([\n#         A.RandomResizedCrop(Config.image_size, Config.image_size, scale=(0.7,1.0),p=0.8),\n#         A.HorizontalFlip(p=0.5),\n        A.Resize(Config.image_size, Config.image_size,p=1),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1),\n        ToTensorV2()], p=1)\n    \n    val_transform = A.Compose([\n    A.Resize(Config.image_size, Config.image_size,p=1),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1),\n    ToTensorV2()], p=1)\n    \n    train_ds = PawDataset(train_ds[\"filepath\"].to_numpy(), train_ds[\"Pawpularity\"].to_numpy(), transforms=train_transform)\n    val_ds = PawDataset(val_ds[\"filepath\"].to_numpy(), val_ds[\"Pawpularity\"].to_numpy(), transforms=val_transform)\n    \n    train_dataloader = DataLoader(train_ds, batch_size=train_batchsize, shuffle=True, pin_memory=True, drop_last=True)\n    val_dataloader = DataLoader(val_ds, batch_size=val_batchsize, shuffle=False, pin_memory=True)\n    \n    return train_dataloader, val_dataloader\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:03:32.109323Z","iopub.execute_input":"2021-11-22T14:03:32.110182Z","iopub.status.idle":"2021-11-22T14:03:32.135168Z","shell.execute_reply.started":"2021-11-22T14:03:32.110141Z","shell.execute_reply":"2021-11-22T14:03:32.134409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training loop","metadata":{}},{"cell_type":"code","source":"for n_fold in range(Config.n_splits):\n    if n_fold in [0]:\n        print(\"Perfoming training for fold:\", n_fold)\n        train_ds = train_df[train_df['n_fold']!=n_fold]\n        val_ds = train_df[train_df['n_fold']==n_fold]\n\n        # preparing the data\n        train_dataloader, val_dataloader = get_dataloaders(train_ds, val_ds, \n                                                          train_batchsize=Config.train_batchsize,\n                                                          val_batchsize=Config.val_batchsize)\n\n        #device\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n        # creating the model\n        model = PawModel(Config.model_name)\n        model = model.to(device)\n\n        # get optimizer\n        optimizer = get_optimizer(model.parameters(), Config)\n\n        # get scheduler \n        scheduler = get_scheduler(optimizer, Config)\n\n        # fp16\n        scaler =None\n        if Config.fp16:\n            scaler = torch.cuda.amp.GradScaler()\n\n        # loss function\n        criterion = RMSELoss()\n\n        # loss history\n        train_loss_history = []\n        val_loss_history = []\n        best_val_loss = float(\"inf\")\n\n        for n_epoch in range(Config.epochs):\n            print(f\"EPOCH {n_epoch}/{Config.epochs}\")\n            avg_train_loss = train_step(model, optimizer, train_dataloader, criterion, device, scaler) \n            train_loss_history.append(avg_train_loss)\n\n            avg_val_loss =  validate_step(model, val_dataloader, criterion, device)\n            val_loss_history.append(avg_val_loss)\n\n            if Config.scheduler == \"ReduceLROnPlateau\":\n                scheduler.step(avg_val_loss)\n            else:\n                scheduler.step()\n\n            # save model\n            if avg_val_loss < best_val_loss:\n                best_val_loss = avg_val_loss\n                model.eval()\n                torch.save(model.state_dict(), os.path.join(\"./\", f\"{Config.model_name}_n_fold_{n_fold}_best.pth\"))\n\n            # Log to wandb\n            wandb.log({\n                f\"fold_{n_fold}_epoch\": n_epoch+1,\n                f\"fold_{n_fold}_train_loss\": avg_train_loss,\n                f\"fold_{n_fold}_val_loss\": avg_val_loss,\n            })\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:03:32.137925Z","iopub.execute_input":"2021-11-22T14:03:32.138396Z","iopub.status.idle":"2021-11-22T15:51:48.845587Z","shell.execute_reply.started":"2021-11-22T14:03:32.138304Z","shell.execute_reply":"2021-11-22T15:51:48.844807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:51:48.85065Z","iopub.execute_input":"2021-11-22T15:51:48.85286Z","iopub.status.idle":"2021-11-22T15:51:55.759141Z","shell.execute_reply.started":"2021-11-22T15:51:48.852815Z","shell.execute_reply":"2021-11-22T15:51:55.758488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:56:23.639421Z","iopub.execute_input":"2021-11-22T15:56:23.639683Z","iopub.status.idle":"2021-11-22T15:56:23.998813Z","shell.execute_reply.started":"2021-11-22T15:56:23.639652Z","shell.execute_reply":"2021-11-22T15:56:23.997858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}